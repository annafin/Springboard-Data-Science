{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Challenge - Machine Learning Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random over and under sampling techniques, we are looking for the best model that represents the behaviors of riders using the rideshare service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler,\n",
    "                                     EditedNearestNeighbours,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     NearMiss)\n",
    "from imblearn.over_sampling import (RandomOverSampler,\n",
    "                                    SMOTE,\n",
    "                                    ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('rider_ml.csv', index_col=0) # import data\n",
    "rider = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38325 entries, 0 to 38324\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   active                  38325 non-null  object \n",
      " 1   Astapor                 38325 non-null  int64  \n",
      " 2   King's Landing          38325 non-null  int64  \n",
      " 3   Winterfell              38325 non-null  int64  \n",
      " 4   Unknown                 38325 non-null  int64  \n",
      " 5   iPhone                  38325 non-null  int64  \n",
      " 6   trips_in_first_30_days  38325 non-null  int64  \n",
      " 7   avg_rating_of_driver    38325 non-null  float64\n",
      " 8   avg_surge               38325 non-null  float64\n",
      " 9   ultimate_black_user     38325 non-null  int64  \n",
      " 10  weekday_pct             38325 non-null  float64\n",
      " 11  avg_dist                38325 non-null  float64\n",
      " 12  avg_rating_by_driver    38325 non-null  float64\n",
      "dtypes: float64(5), int64(7), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "rider.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>Astapor</th>\n",
       "      <th>King's Landing</th>\n",
       "      <th>Winterfell</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>iPhone</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>ultimate_black_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>46.2</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0</td>\n",
       "      <td>82.4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  active  Astapor  King's Landing  Winterfell  Unknown  iPhone  \\\n",
       "0     No        0               1           0        0       1   \n",
       "1     No        1               0           0        0       0   \n",
       "2     No        1               0           0        0       1   \n",
       "3     No        0               1           0        0       1   \n",
       "4     No        0               0           1        0       0   \n",
       "\n",
       "   trips_in_first_30_days  avg_rating_of_driver  avg_surge  \\\n",
       "0                       4                   4.7       1.10   \n",
       "1                       0                   5.0       1.00   \n",
       "2                       3                   4.3       1.00   \n",
       "3                       9                   4.6       1.14   \n",
       "4                      14                   4.4       1.19   \n",
       "\n",
       "   ultimate_black_user  weekday_pct  avg_dist  avg_rating_by_driver  \n",
       "0                    1         46.2      3.67                   5.0  \n",
       "1                    0         50.0      8.26                   5.0  \n",
       "2                    0        100.0      0.77                   5.0  \n",
       "3                    1         80.0      2.36                   4.9  \n",
       "4                    0         82.4      3.13                   4.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rider.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    print('Logistic Regression \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "\n",
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Random Forest Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', rf.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', rf.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes\n",
    "\n",
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gaussian = GaussianNB().fit(X_train, y_train)\n",
    "    y_pred = gaussian.predict(X_test)\n",
    "    \n",
    "    print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28743, 12) (28743,)\n",
      "(9582, 12) (9582,)\n"
     ]
    }
   ],
   "source": [
    "# separate target variable \n",
    "y = rider['active'].values\n",
    "X = rider.drop('active', axis=1).values\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Under Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random undersampling Counter({'No': 78, 'Yes': 78})\n",
      "(117, 12) (117,)\n",
      "(39, 12) (39,)\n"
     ]
    }
   ],
   "source": [
    "random_under = RandomUnderSampler(random_state=42)\n",
    "X_rs, y_rs = random_under.fit_sample(X, y)\n",
    "\n",
    "print('Random undersampling {}'.format(Counter(y_rs)))\n",
    "\n",
    "# train test split\n",
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_rs, y_rs, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_rs.shape, y_train_rs.shape)\n",
    "print(X_test_rs.shape, y_test_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.7435897435897436\n",
      "Accuracy Score, Test Set:  0.6666666666666666\n",
      "\n",
      "Confusion Matrix: \n",
      " [[12  6]\n",
      " [ 7 14]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.63      0.67      0.65        18\n",
      "         Yes       0.70      0.67      0.68        21\n",
      "\n",
      "    accuracy                           0.67        39\n",
      "   macro avg       0.67      0.67      0.67        39\n",
      "weighted avg       0.67      0.67      0.67        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.5897435897435898\n",
      "Confusion Matrix: \n",
      " [[12  6]\n",
      " [10 11]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.55      0.67      0.60        18\n",
      "         Yes       0.65      0.52      0.58        21\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.60      0.60      0.59        39\n",
      "weighted avg       0.60      0.59      0.59        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "decision_tree(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.5897435897435898\n",
      "Confusion Matrix: \n",
      " [[12  6]\n",
      " [10 11]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.55      0.67      0.60        18\n",
      "         Yes       0.65      0.52      0.58        21\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.60      0.60      0.59        39\n",
      "weighted avg       0.60      0.59      0.59        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "random_forest(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.7264957264957265\n",
      "Accuracy Score, Test Set: 0.5897435897435898\n",
      "Confusion Matrix: \n",
      " [[12  6]\n",
      " [10 11]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.55      0.67      0.60        18\n",
      "         Yes       0.65      0.52      0.58        21\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.60      0.60      0.59        39\n",
      "weighted avg       0.60      0.59      0.59        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'No': 38002, 'Yes': 78})\n",
      "(28560, 12) (28560,)\n",
      "(9520, 12) (9520,)\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "X_enn, y_enn = enn.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_enn)))\n",
    "\n",
    "# train test split\n",
    "X_train_enn, X_test_enn, y_train_enn, y_test_enn = train_test_split(X_enn, y_enn, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_enn.shape, y_train_enn.shape)\n",
    "print(X_test_enn.shape, y_test_enn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.9979341736694678\n",
      "Accuracy Score, Test Set:  0.9980042016806723\n",
      "\n",
      "Confusion Matrix: \n",
      " [[9501    0]\n",
      " [  19    0]]\n",
      "\n",
      "Classification Report \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9501\n",
      "         Yes       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           1.00      9520\n",
      "   macro avg       0.50      0.50      0.50      9520\n",
      "weighted avg       1.00      1.00      1.00      9520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9934873949579832\n",
      "Confusion Matrix: \n",
      " [[9458   43]\n",
      " [  19    0]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9501\n",
      "         Yes       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.99      9520\n",
      "   macro avg       0.50      0.50      0.50      9520\n",
      "weighted avg       1.00      0.99      0.99      9520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "decision_tree(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9980042016806723\n",
      "Confusion Matrix: \n",
      " [[9501    0]\n",
      " [  19    0]]\n",
      "\n",
      "Classification Report \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9501\n",
      "         Yes       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           1.00      9520\n",
      "   macro avg       0.50      0.50      0.50      9520\n",
      "weighted avg       1.00      1.00      1.00      9520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "random_forest(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.9807422969187675\n",
      "Accuracy Score, Test Set: 0.9786764705882353\n",
      "Confusion Matrix: \n",
      " [[9316  185]\n",
      " [  18    1]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.98      0.99      9501\n",
      "         Yes       0.01      0.05      0.01        19\n",
      "\n",
      "    accuracy                           0.98      9520\n",
      "   macro avg       0.50      0.52      0.50      9520\n",
      "weighted avg       1.00      0.98      0.99      9520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'No': 78, 'Yes': 78})\n",
      "(117, 12) (117,)\n",
      "(39, 12) (39,)\n"
     ]
    }
   ],
   "source": [
    "nm = NearMiss()\n",
    "X_nm, y_nm = nm.fit_resample(X, y)\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_nm)))\n",
    "\n",
    "# train test split\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nm, y_nm, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_nm.shape, y_train_nm.shape)\n",
    "print(X_test_nm.shape, y_test_nm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.7777777777777778\n",
      "Accuracy Score, Test Set:  0.7435897435897436\n",
      "\n",
      "Confusion Matrix: \n",
      " [[15  3]\n",
      " [ 7 14]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.83      0.75        18\n",
      "         Yes       0.82      0.67      0.74        21\n",
      "\n",
      "    accuracy                           0.74        39\n",
      "   macro avg       0.75      0.75      0.74        39\n",
      "weighted avg       0.76      0.74      0.74        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.8205128205128205\n",
      "Confusion Matrix: \n",
      " [[13  5]\n",
      " [ 2 19]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.72      0.79        18\n",
      "         Yes       0.79      0.90      0.84        21\n",
      "\n",
      "    accuracy                           0.82        39\n",
      "   macro avg       0.83      0.81      0.82        39\n",
      "weighted avg       0.83      0.82      0.82        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "decision_tree(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.8717948717948718\n",
      "Confusion Matrix: \n",
      " [[16  2]\n",
      " [ 3 18]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.89      0.86        18\n",
      "         Yes       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.87        39\n",
      "   macro avg       0.87      0.87      0.87        39\n",
      "weighted avg       0.87      0.87      0.87        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "random_forest(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.7606837606837606\n",
      "Accuracy Score, Test Set: 0.6153846153846154\n",
      "Confusion Matrix: \n",
      " [[17  1]\n",
      " [14  7]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.55      0.94      0.69        18\n",
      "         Yes       0.88      0.33      0.48        21\n",
      "\n",
      "    accuracy                           0.62        39\n",
      "   macro avg       0.71      0.64      0.59        39\n",
      "weighted avg       0.72      0.62      0.58        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Cleaning Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'No': 78, 'Yes': 78})\n",
      "(117, 12) (117,)\n",
      "(39, 12) (39,)\n"
     ]
    }
   ],
   "source": [
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_ncr, y_ncr = nm.fit_resample(X, y)\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ncr)))\n",
    "\n",
    "# train test split\n",
    "X_train_ncr, X_test_ncr, y_train_ncr, y_test_ncr = train_test_split(X_ncr, y_ncr, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_ncr.shape, y_train_ncr.shape)\n",
    "print(X_test_ncr.shape, y_test_ncr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.7777777777777778\n",
      "Accuracy Score, Test Set:  0.7435897435897436\n",
      "\n",
      "Confusion Matrix: \n",
      " [[15  3]\n",
      " [ 7 14]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.83      0.75        18\n",
      "         Yes       0.82      0.67      0.74        21\n",
      "\n",
      "    accuracy                           0.74        39\n",
      "   macro avg       0.75      0.75      0.74        39\n",
      "weighted avg       0.76      0.74      0.74        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg(X_train_ncr, X_test_ncr, y_train_ncr, y_test_ncr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.8205128205128205\n",
      "Confusion Matrix: \n",
      " [[13  5]\n",
      " [ 2 19]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.72      0.79        18\n",
      "         Yes       0.79      0.90      0.84        21\n",
      "\n",
      "    accuracy                           0.82        39\n",
      "   macro avg       0.83      0.81      0.82        39\n",
      "weighted avg       0.83      0.82      0.82        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "decision_tree(X_train_ncr, X_test_ncr, y_train_ncr, y_test_ncr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.8717948717948718\n",
      "Confusion Matrix: \n",
      " [[16  2]\n",
      " [ 3 18]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.89      0.86        18\n",
      "         Yes       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.87        39\n",
      "   macro avg       0.87      0.87      0.87        39\n",
      "weighted avg       0.87      0.87      0.87        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "random_forest(X_train_ncr, X_test_ncr, y_train_ncr, y_test_ncr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.7606837606837606\n",
      "Accuracy Score, Test Set: 0.6153846153846154\n",
      "Confusion Matrix: \n",
      " [[17  1]\n",
      " [14  7]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.55      0.94      0.69        18\n",
      "         Yes       0.88      0.33      0.48        21\n",
      "\n",
      "    accuracy                           0.62        39\n",
      "   macro avg       0.71      0.64      0.59        39\n",
      "weighted avg       0.72      0.62      0.58        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian(X_train_ncr, X_test_ncr, y_train_ncr, y_test_ncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'No': 38247, 'Yes': 38247})\n",
      "(57370, 12) (57370,)\n",
      "(19124, 12) (19124,)\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ros)))\n",
    "\n",
    "# train test split\n",
    "X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_ros.shape, y_train_ros.shape)\n",
    "print(X_test_ros.shape, y_test_ros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.646696879902388\n",
      "Accuracy Score, Test Set:  0.6489751098096632\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5922 3669]\n",
      " [3044 6489]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.66      0.62      0.64      9591\n",
      "         Yes       0.64      0.68      0.66      9533\n",
      "\n",
      "    accuracy                           0.65     19124\n",
      "   macro avg       0.65      0.65      0.65     19124\n",
      "weighted avg       0.65      0.65      0.65     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_ros, X_test_ros, y_train_ros, y_test_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9991633549466639\n",
      "Confusion Matrix: \n",
      " [[9575   16]\n",
      " [   0 9533]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9591\n",
      "         Yes       1.00      1.00      1.00      9533\n",
      "\n",
      "    accuracy                           1.00     19124\n",
      "   macro avg       1.00      1.00      1.00     19124\n",
      "weighted avg       1.00      1.00      1.00     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_ros, X_test_ros, y_train_ros, y_test_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 1.0\n",
      "Confusion Matrix: \n",
      " [[9591    0]\n",
      " [   0 9533]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9591\n",
      "         Yes       1.00      1.00      1.00      9533\n",
      "\n",
      "    accuracy                           1.00     19124\n",
      "   macro avg       1.00      1.00      1.00     19124\n",
      "weighted avg       1.00      1.00      1.00     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_ros, X_test_ros, y_train_ros, y_test_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.691075474986927\n",
      "Accuracy Score, Test Set: 0.6963501359548212\n",
      "Confusion Matrix: \n",
      " [[6445 3146]\n",
      " [2661 6872]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.71      0.67      0.69      9591\n",
      "         Yes       0.69      0.72      0.70      9533\n",
      "\n",
      "    accuracy                           0.70     19124\n",
      "   macro avg       0.70      0.70      0.70     19124\n",
      "weighted avg       0.70      0.70      0.70     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_ros, X_test_ros, y_train_ros, y_test_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'No': 38247, 'Yes': 38247})\n",
      "(57370, 12) (57370,)\n",
      "(19124, 12) (19124,)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_sm)))\n",
    "\n",
    "# train test split\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_sm.shape, y_train_sm.shape)\n",
    "print(X_test_sm.shape, y_test_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.6759456161757016\n",
      "Accuracy Score, Test Set:  0.6771595900439239\n",
      "\n",
      "Confusion Matrix: \n",
      " [[6130 3461]\n",
      " [2713 6820]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.69      0.64      0.67      9591\n",
      "         Yes       0.66      0.72      0.69      9533\n",
      "\n",
      "    accuracy                           0.68     19124\n",
      "   macro avg       0.68      0.68      0.68     19124\n",
      "weighted avg       0.68      0.68      0.68     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9958690650491528\n",
      "Confusion Matrix: \n",
      " [[9548   43]\n",
      " [  36 9497]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9591\n",
      "         Yes       1.00      1.00      1.00      9533\n",
      "\n",
      "    accuracy                           1.00     19124\n",
      "   macro avg       1.00      1.00      1.00     19124\n",
      "weighted avg       1.00      1.00      1.00     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9979606776824932\n",
      "Confusion Matrix: \n",
      " [[9587    4]\n",
      " [  35 9498]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9591\n",
      "         Yes       1.00      1.00      1.00      9533\n",
      "\n",
      "    accuracy                           1.00     19124\n",
      "   macro avg       1.00      1.00      1.00     19124\n",
      "weighted avg       1.00      1.00      1.00     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.7518215094997386\n",
      "Accuracy Score, Test Set: 0.7575820957958586\n",
      "Confusion Matrix: \n",
      " [[6713 2878]\n",
      " [1758 7775]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.70      0.74      9591\n",
      "         Yes       0.73      0.82      0.77      9533\n",
      "\n",
      "    accuracy                           0.76     19124\n",
      "   macro avg       0.76      0.76      0.76     19124\n",
      "weighted avg       0.76      0.76      0.76     19124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'No': 38247, 'Yes': 38218})\n",
      "(57370, 12) (57370,)\n",
      "(19124, 12) (19124,)\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(random_state=42)\n",
    "X_ada, y_ada = ada.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ada)))\n",
    "\n",
    "# train test split\n",
    "X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada, y_ada, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_sm.shape, y_train_sm.shape)\n",
    "print(X_test_sm.shape, y_test_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.6751586803375881\n",
      "Accuracy Score, Test Set:  0.6726996913741696\n",
      "\n",
      "Confusion Matrix: \n",
      " [[6134 3400]\n",
      " [2857 6726]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.64      0.66      9534\n",
      "         Yes       0.66      0.70      0.68      9583\n",
      "\n",
      "    accuracy                           0.67     19117\n",
      "   macro avg       0.67      0.67      0.67     19117\n",
      "weighted avg       0.67      0.67      0.67     19117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9967045038447455\n",
      "Confusion Matrix: \n",
      " [[9500   34]\n",
      " [  29 9554]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9534\n",
      "         Yes       1.00      1.00      1.00      9583\n",
      "\n",
      "    accuracy                           1.00     19117\n",
      "   macro avg       1.00      1.00      1.00     19117\n",
      "weighted avg       1.00      1.00      1.00     19117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 1.0\n",
      "Accuracy Score, Test Set: 0.9983784066537637\n",
      "Confusion Matrix: \n",
      " [[9532    2]\n",
      " [  29 9554]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      9534\n",
      "         Yes       1.00      1.00      1.00      9583\n",
      "\n",
      "    accuracy                           1.00     19117\n",
      "   macro avg       1.00      1.00      1.00     19117\n",
      "weighted avg       1.00      1.00      1.00     19117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.7514298667782661\n",
      "Accuracy Score, Test Set: 0.7538839776115499\n",
      "Confusion Matrix: \n",
      " [[6725 2809]\n",
      " [1896 7687]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.78      0.71      0.74      9534\n",
      "         Yes       0.73      0.80      0.77      9583\n",
      "\n",
      "    accuracy                           0.75     19117\n",
      "   macro avg       0.76      0.75      0.75     19117\n",
      "weighted avg       0.76      0.75      0.75     19117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
